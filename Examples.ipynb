{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Артем Жук, 399 группа\n",
    "### EM for PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном репозитории реализованы две вариации ЕМ-алогоритма для анализа главных компонент. Статья с описанием выкладок: http://www.machinelearning.ru/wiki/images/7/73/BMMO11_11.pdf\n",
    "Интерфейсы классов следуют интерфейсу sklearn.decomposition.PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EMPCA\n",
    "Класс EMPCA является реализацией ЕМ алгоритма для нахожения подпространста пространства признаков, порожденного первыми несколькими главными компонентами. Для всей выборки все признаки должны быть известны.  \n",
    "Эта реализация опирается на достаточно простые выкладки, а кроме того быстрее работает, чем более общая реализация EMPCAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from empca import EMPCA\n",
    "from empca_missing import EMPCAM\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from utils import random_model, gram_schmidt, span_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку. Метод random_model(N, D, d) генрирует выборку с распределением $W\\mathcal{N}(0, I_d) + \\mathcal{N}(0, \\varepsilon I_D), W\\in M(\\mathbb{R})^{D\\times d}$.  \n",
    "gram_schmidt(X) применяет алгоритм Грама-Шмидта к строкам Х."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=\n",
      " [[ 0.80766511 -3.04284396 -7.51495146 -2.84949247  8.19801441  3.85179355]]\n",
      "X..=\n",
      " [[  1.1084357   -1.30820071  -4.90895327  -1.29960592   5.21991388\n",
      "    2.03144389]\n",
      " [  0.64571353  -0.07770269   0.33014706   0.96793423   0.51394842\n",
      "   -1.09151779]\n",
      " [ -0.49807375   6.07875637  14.54139686   4.59016023 -15.15980614\n",
      "   -7.01616932]\n",
      " [  0.6132104   -2.08348901  -4.39644375  -1.28185953   4.0174445\n",
      "    2.21811061]\n",
      " [ -0.48082356  -1.57492028  -1.43134362  -1.17329032   3.92875899\n",
      "    1.38834662]]\n"
     ]
    }
   ],
   "source": [
    "X, W, T = random_model(30, 6, 1)\n",
    "print(\"W=\\n\", W)\n",
    "print(\"X..=\\n\", X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр EMPCA и запустим на нашей выборке. Поле components_ содержит ортнормированный базис из n_components главных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basis:\n",
      " [[ 0.06202824 -0.25136142 -0.59813343 -0.21025565  0.65882458  0.31136646]]\n",
      "original basis:\n",
      " [[ 0.06455146 -0.24319488 -0.60062157 -0.22774154  0.65521438  0.307849  ]]\n"
     ]
    }
   ],
   "source": [
    "empca = EMPCA(n_components=1, n_iter=100)\n",
    "empca.fit(X)\n",
    "print('basis:\\n', empca.components_)\n",
    "print('original basis:\\n', gram_schmidt(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, алгоритм довольно точно определил направляющий вектор прямой, на которой лежат точки. Попробуем для плоскости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basis:\n",
      " [[-0.5489386  -0.49993188 -0.03774341  0.42446507  0.05264976  0.14070607\n",
      "   0.49453935]]\n",
      "original basis:\n",
      " [[ 0.23292482  0.39597175  0.37400723  0.41763673 -0.26639632  0.48520001\n",
      "   0.41020057]\n",
      " [-0.3110128  -0.51832853  0.25675356  0.46399796  0.40561628 -0.14779748\n",
      "   0.40868253]\n",
      " [ 0.36365973 -0.12515884 -0.06939373 -0.03267816  0.66467168  0.58498271\n",
      "  -0.24941992]\n",
      " [ 0.56124689 -0.06540257 -0.1778197   0.62363422 -0.07967346 -0.39302888\n",
      "  -0.31522278]\n",
      " [ 0.27302376  0.29935704  0.66674498 -0.27267756  0.34488873 -0.44427164\n",
      "  -0.02481841]]\n"
     ]
    }
   ],
   "source": [
    "X, W, T = random_model(60, 7, 5)\n",
    "empca = EMPCA(n_components=1, n_iter=100)\n",
    "empca.fit(X)\n",
    "print('basis:\\n', empca.components_)\n",
    "print('original basis:\\n', gram_schmidt(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз сложнее проверить совпадение векторов. Однако для проверки корректности нам можно проверять не точное совпадение базисов, а совпадение подпростраств, на них натянутых. Для этого воспользуемся функцией span_in(A, B), проверяющей что строки А лежат в линейной оболочке строк B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span_in:  True\n"
     ]
    }
   ],
   "source": [
    "print('span_in: ', span_in(empca.components_, gram_schmidt(W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним работу нашего преобразователя со стандартным sklearn.decomposition.PCA. Для этого сравним explained_variance_ratio_. Это доля дисперсии, приходящаяся на компоненту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d2435fdf66f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mempca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEMPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_model' is not defined"
     ]
    }
   ],
   "source": [
    "X, W, T = random_model(100, 50, 10)\n",
    "pca = PCA(n_components=5)\n",
    "empca = EMPCA(n_components=5, n_iter=100)\n",
    "\n",
    "pca.fit(X)\n",
    "empca.fit(X)\n",
    "\n",
    "print('pca ratio:\\n', pca.explained_variance_ratio_)\n",
    "print('empca ratio:\\n', empca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, за 300 итерация численный алгоритм достаточно точно нашел "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EMPCAM\n",
    "Этот класс реализует тот же алгоритм, но допускает пропуски в данных. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгененрируем выборку с 20% пропущенных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=\n",
      " [[ -9.47924135  -0.32400759  -7.913485   -11.91856188          nan\n",
      "  -11.31533725  10.29606614  13.48421466  13.05817822 -14.13734944]\n",
      " [  1.00126044  -0.0626547           nan   2.09166539   0.36436707\n",
      "           nan  -0.49722563  -1.63446161  -1.26188072   1.45114822]\n",
      " [  0.09880113  -0.06869992  -0.75409562  -0.97428673  -0.5677724\n",
      "   -1.56886931  -0.70074102   0.25233626   1.02794643  -1.47462933]\n",
      " [ -7.02853431  -2.21500292  -4.68553497  -7.4146958   -3.22222511\n",
      "   -6.93384712   7.77246359   8.1219654    8.58026932          nan]\n",
      " [ -1.19193611          nan  -0.59327046          nan          nan\n",
      "   -2.91422686   1.40294254   2.24571149   1.98331364  -1.67194105]]\n"
     ]
    }
   ],
   "source": [
    "X, W, T = random_model(100, 10, 1, 0.2)\n",
    "print(\"X=\\n\", X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И применим к ней алгоритм: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found basis:  [[-0.31322081 -0.01709025 -0.2135308  -0.38589466 -0.12226821 -0.33903985\n",
      "   0.31082277  0.42163399  0.38071988 -0.39731521]]\n",
      "original basis:  [[ 0.2998815   0.02451015  0.21120959  0.35437946  0.12519969  0.36332475\n",
      "  -0.32616408 -0.40678102 -0.38342535  0.41560488]]\n",
      "A - B:  [-0.6131023  -0.04160039 -0.42474039 -0.74027412 -0.24746789 -0.7023646\n",
      "  0.63698684  0.82841501  0.76414523 -0.81292009]\n",
      "diff =  1.99934295796\n"
     ]
    }
   ],
   "source": [
    "empcam = EMPCAM(n_components=1, n_iter=100)\n",
    "empcam.fit(X)\n",
    "A = empcam.components_\n",
    "B = gram_schmidt(W)\n",
    "print('found basis: ', A)\n",
    "print('original basis: ', B)\n",
    "d = A[0] - B[0]\n",
    "print('A - B: ', d)\n",
    "print('diff = ', np.linalg.norm(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, нам удалось довольно точно восстановить исходную зависимость. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь построим модель с большим числом латентных переменных и проверим, что найденное подпрастранство попадает в пространство, натянутое на образы латентных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lies_inside:  True\n"
     ]
    }
   ],
   "source": [
    "X, W, T = random_model(100, 30, 5, 0.1)\n",
    "empcam = EMPCAM(n_components=2, n_iter=200)\n",
    "empcam.fit(X)\n",
    "print('lies_inside: ', span_in(empcam.components_, gram_schmidt(W)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
